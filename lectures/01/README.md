# Lecture 01 - Kubernetes fundamentals

## Introduction to the instructors

![Kasper Svane](https://media.licdn.com/dms/image/v2/C5603AQEpw3hdYCmKfA/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1516890090769?e=1728518400&v=beta&t=KYbU3Gv4E7gx0q76cAug3-lbIPxTxQwNsogFwxAKNL0)

- 9th semester Software Engineering student
- Industry for 3 years
  - Software Engineer ~ KeyShot
  - Software Engineer ~ Digizuite
- Studying Master of Science in Software Engineering ~ University of Southern Denmark
- Bachelor in Engineering in Software Engineering ~ University of Southern Denmark
- LinkedIn ~ [linkedin.com/in/kasper-svane](https://www.linkedin.com/in/kasper-svane-706303b9/)

### Anders Launer Bæk-Petersen

![Anders Launer Bæk-Petersen](https://avatars.githubusercontent.com/u/28479232?v=4)

- PhD Fellow ~ SDU Software Engineering
    - Understanding the Reliability of Machine Learning
Systems from a Software Engineering Perspective
- PhD Fellow ~ SDU Center for Energy Informatics
    - Transferable AI Model Development Framework for Smart Energy Systems
- Industry for 4,5 years
    - Machine Learning Engineer ~ Energinet
    - Data Scientist ~ Esoft R&D
    - Research Assistant ~ Technical University of Denmark
- Master of Science in Mathematical Modelling and Computation ~ Technical University of Denmark
- Bachelor of Science in Robot Systems ~ University of Southern Denmark
- LinkedIn ~ [linkedin.com/in/anderslaunerbaek](https://www.linkedin.com/in/anderslaunerbaek/)

## Exercise lectures

The format of the exercise lectures is as follows:

- Two modules of 45 minutes each per week.
- The first half of the first module will be used to recap and solution sharing from the previous exercises. The reminder of the first module and the second module will be used to work the exercises for the current week.
- The exercises will be hands-on exercises where you will be working with Kubernetes and the themes of this week's lecture.
- The exercises will be provided in `README.md` file in the respective lecture folder.

Please open issues [here](https://github.com/jakobhviid/BigDataCourseExercises/issues) if you encounter unclear information or experience bugs in our examples!

## Subject and objective for these exercises

The exercises for the first lecture are to introduce and refresh the necessary components and terminology of Kubernetes. The below-mentioned material has been sourced from [https://kubernetes.io/docs/tutorials/kubernetes-basics](https://kubernetes.io/docs/tutorials/kubernetes-basics/) and familiarizing with this content will be sufficient for progressing along the exercises.

The objective of this lecture is to provide the foundation for future exercise sessions and for the semester project.

## Brief introduction to Kubernetes

Kubernetes was one of the answers to moving from pure virtualization towards infrastructure as a service and being the convenient abstraction for decoupling applications and the underlying hardware.

We recommend watching the documentary [Kubernetes: The Documentary [PART 1]](https://youtu.be/BE77h7dmoQU?si=qohxiWDd52EpPoHP) and [Kubernetes: The Documentary [PART 2]](https://youtu.be/318elIq37PE?si=_Pjgstj7w_9OlsUf) to get context and history of the preliminary enablers for Kubernetes.

### [Kubernetes Basics](https://kubernetes.io/docs/tutorials/kubernetes-basics/)

Kubernetes is a cluster orchestration system that enables the deployment of containerised applications on virtualized hardware or bare metal hardware.

> Kubernetes is a production-grade, open-source platform that orchestrates the placement (scheduling) and execution of application containers within and across computer clusters.
*[kubernetes.io - Cluster Diagram. (Accessed: 04 September 2023)](https://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/)*

The diagram below illustrates the core components of a Kubernetes cluster. The Kubernetes cluster consists of one or multiple nodes that execute the application processes and control plane resource that coordinates the application activities across the nodes.

![Kubernetes Cluster](https://d33wubrfki0l68.cloudfront.net/283cc20bb49089cb2ca54d51b4ac27720c1a7902/34424/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg)
*Image from [kubernetes.io - Cluster Diagram. (Accessed: 04 September 2023)](https://d33wubrfki0l68.cloudfront.net/283cc20bb49089cb2ca54d51b4ac27720c1a7902/34424/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg)*

### [Using kubectl to Create a Deployment](https://kubernetes.io/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/)

A Kubernetes deployment is the recipe for running your application. The control plane will constantly monitor the state of the application and provide self-healing actions if the current application instance is unresponsive.

![ Deploying your first app on Kubernetes](https://d33wubrfki0l68.cloudfront.net/8700a7f5f0008913aa6c25a1b26c08461e4947c7/cfc2c/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg)
*Image from [kubernetes.io - Deploying your first app on Kubernetes. (Accessed: 04 September 2023)](https://d33wubrfki0l68.cloudfront.net/8700a7f5f0008913aa6c25a1b26c08461e4947c7/cfc2c/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg)*

`kubectl` is the CLI for Kubernetes and the CLI can be used to create a deployment of containerized applications or manage already deployed applications, fetch logs from the application, and much more.

### [Viewing Pods and Nodes](https://kubernetes.io/docs/tutorials/kubernetes-basics/explore/explore-intro/)

#### Pods

A Kubernetes Pod is an abstraction generated by a Kubernetes deployment. The Pod behaves as a logical host and is hosting one or multiple containerized applications as illustrated in the figure below.

![Pods overview](https://d33wubrfki0l68.cloudfront.net/fe03f68d8ede9815184852ca2a4fd30325e5d15a/98064/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg)
*Image from [kubernetes.io - Pods overview. (Accessed: 04 September 2023)](https://d33wubrfki0l68.cloudfront.net/fe03f68d8ede9815184852ca2a4fd30325e5d15a/98064/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg)*

#### Nodes

A Kubernetes node can be described as a worker within the Kubernetes cluster. The node is managed by the control plane and can host several different Pods as illustrated in the figure below.
![Node overview](https://d33wubrfki0l68.cloudfront.net/5cb72d407cbe2755e581b6de757e0d81760d5b86/a9df9/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg)
*Image from [kubernetes.io - Node overview. (Accessed: 04 September 2023)](https://d33wubrfki0l68.cloudfront.net/5cb72d407cbe2755e581b6de757e0d81760d5b86/a9df9/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg)*

### [Using a Service to Expose Your App](https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/)

Each Kubernetes Pod has a different IP address as seen in the figure above. These IP addresses are local to the cluster and not accessible from outside the cluster. For some applications, we need to have an abstraction, which maps external traffic to the deployment (Pod) of interest. The Pods have a lifecycle and their IP address change due to rescheduling to another node.

![Services and Labels](https://d33wubrfki0l68.cloudfront.net/7a13fe12acc9ea0728460c482c67e0eb31ff5303/2c8a7/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg)
*Image from [kubernetes.io - Services and Labels. (Accessed: 04 September 2023)](https://d33wubrfki0l68.cloudfront.net/7a13fe12acc9ea0728460c482c67e0eb31ff5303/2c8a7/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg)*

A Kubernetes Service is the abstraction we need to provide a loosely coupling Pods and external traffic. There are multiple types of Services:

- ClusterIP
- NodePort
- LoadBalancer
- ExternalName

Get full definitions here: [Overview of Kubernetes Services](https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/)

> A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods. 
*[kubernetes.io - Using a Service to Expose Your App. (Accessed: 04 September 2023)](https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/)*

## Exercises

### Exercise 1 - Kubernetes setup

#### The kubectl CLI

The CLI tool used to communicate with a Kubernetes cluster from your localhost is called "kubectl". It is used though the terminal like `kubectl <command> <flags>`.
You read more about the CLI and how to install it here: [install kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl).

#### The kubeconfig file

You will receive a kubeconfig file before starting on lecture 1. Your personal config file will be shared by email and is needed to access the Kubernetes cluster.

The kubeconfig file is located in the `~/.kube` directory in your home directory. The file is named `config` and is used by default when running the `kubectl` command.
The kubeconfig file contains the necessary information to connect to the cluster and authenticate with it. The file is used by the `kubectl` CLI to connect to the cluster.

**Task**: Please update the `~/.kube/config` file with the provided content.

**Note**: You are able to specify the kubeconfig file to use by using the `--kubeconfig` flag.

#### Wrap up

> All the following exercises assume you have access to the Kubernetes cluster and the `kubectl` CLI installed on your local host.

### Exercise 2 - Deploy "Hello World" application

The first thing you will be doing with the Kubernetes cluster is to deploy a hello world application. The application can be found on GitHub [paulbouwer/hello-kubernetes](https://github.com/paulbouwer/hello-kubernetes). A yaml file to deploy the application can be found [here](./hello-kubernetes.yaml).

The yaml file contains two resources, a deployment and a service. Deployments are used to create pods, and services are used to route traffic to the pods using label selectors. A major part of Kubernetes is the use of labels and selectors. Labels are key-value pairs that can be used for filtering.

Inspect the yaml manifest and understand the different parts of it:

- Identify the two resources.
- Identify the labels and selectors. How are they used?
- Try to understand how the environment variables are added to the pods.

Now that you have looked through the yaml you may have figured out the following:

- The deployment creates 3 pods.
- The pods have 3 environment variables that use a `fieldRef`.
- The container listens on port 8080.
- The service listens for traffic on port 8080 and routes it to port 8080 inside the pod.

The `fieldRef` inside the environment variables is used to reference a field of the pod and use the value of it as an environment variable.

- `metadata.namespace` is used to reference the namespace that the pod is inside. When no namespace is provided for a resource, then the "default" namespace is used.
- `metadata.name` is used to reference the name of the pod. The name is automatically generated using the name of the replica set + a random string for each pod. The name of the replicaset comes from the name of the deployment + a hash to uniquely identify the revision.
- `spec.nodeName` is used to reference the name of the node that the pod is scheduled to run on.

Now that you understand the yaml file, run the command `kubectl apply -f hello-kubernetes.yaml` to apply the resources to the Kubernetes cluster. You can then use `kubectl get pods` to get a list of the pods and `kubectl get service` to get a list of the services.

### Exercise 3 - Connecting to the application

Now that you have deployed the application the next step is to try and connect to it. The application is an HTTP server that listens for requests on port 8080. To connect to the application, we should do it through the service.

Connecting to a service can be done in different ways. The simplest way to connect to a service inside the cluster and to your localhost is by running the `kubectl port-forward` command.

#### Use port forwarding

To use the `kubectl port-forward` command, run the following command `kubectl port-forward svc/<name of service> <localhost port>:<service port>`. The command will open a port on your localhost and forward traffic to a port on the service. In this case, use port `8080` for both your localhost and service (`kubectl port-forward svc/hello-kubernetes 8080`).
Please feel free to change it to something different. Example to `9000:8080` to use port 9000 on your localhost and forward the traffic to port 8080 on the service. Open a browser and navigate to [http://localhost:8080](http://localhost:8080) to access your deployed application.

#### Interact with the application

Now that you can connect to the application, try and understand the web page. The webpage gives different information about the pod that was handling your request. It displays the pod name, the namespace the pod is inside, and the node that the pod is running on.

Try to refresh the webpage a few times and notice how the values change. You should see that the name of the pod changes. This is because the request was routed to a different pod.

### Exercise 4 - Scaling the application

Some applications are designed to have multiple instances running. In the case of the hello-kubernetes application, you can increase and decrease the amount of replicas with no problem. It may be desirable to scale your deployment up or down to match the demand of the application. There are two ways to scale deployments in Kubernetes - manual, or automatic. Automatic scaling will not be covered in this exercise.

To manually scale a deployment, you would modify the `replicas` field of the deployment resource. This can be done by either modifying the yaml file and reapplying it, or by using the edit command. To edit the deployment using the edit command, use the following: `kubectl edit deployment/hello-kubernetes`. This will open a window with your default text editor. Simply modify the file, save it, and close the window to modify the resource.

1. Try to change the replica count to 5.
2. Check that the amount of pods has changed to 5
3. Try accessing the application to verify it still works
4. Change the replicas back to 3
5. Check that the amount of pods has changed to 3
6. Try accessing the application to verify it still works

When scaling the amount of replicas, the service will automatically start/stop routing traffic to the new/old pods without disrupting existing connections.

### Exercise 5 - Deploy the application using Helm

[Helm](https://helm.sh/) is a package manager for Kubernetes. Helm simplifies the process of deploying and managing applications on Kubernetes by providing a standardized way to package, distribute and manage Kubernetes resources. Helm packares are called "charts". A chart is a collection of files that describes a set of Kubernetes resources along with configurations. Charts can be customized to suit specific deployment requirements.

To install Helm go to their [install](https://helm.sh/docs/intro/install/) guide.

The hello-kubernetes application that you deployed earlier has a Helm chart. Go to the repository [paulbouwer/hello-kubernetes](https://github.com/paulbouwer/hello-kubernetes) on GitHub and download / clone.

To install the chart using the default `values`, simply open a terminal inside the hello-kubernetes repository you just cloned and type the command `helm install hello-kubernetes-helm ./deploy/helm/hello-kubernetes`. This will install the Helm Chart located at `./deploy/helm/hello-kubernetes` and give the release the name "hello-kubernetes". You can see the status of the Helm release using `helm status hello-kubernetes-helm`. Get a list of the pods and services and see what was created.

You should see that it created 2 pods and 1 service. This is similar to the deployment you made before, except this is installed using Helm. But now that it is installed you should try to connect to it like before, just remember that the service is now called something different. Hint: `kubectl get services`.

A Helm chart can be configured using `values`. The default `values` can be found inside the Helm chart. Open the file located at `./deploy/helm/hello-kubernetes/values.yaml` in the repository and see the different values. We want to try to increase the amount of replicas using the `deployment.replicaCount` value. Because we want to modify an existing release, we need to use the `helm upgrade` command. Use `helm upgrade hello-kubernetes-helm ./deploy/helm/hello-kubernetes --set deployment.replicaCount=5` to set the replica count to 5. Now get a list of the pods and notice how the amount of pods changed.

You can get a list of all Helm releases in the default namespace using the following command `helm list`.

### Exercise 6 - Interactive container

Similarly to Docker, you can interact and get a shell of a running container in Kubernetes.
First, we will try to get a shell inside an existing container. The command to execute commands inside containers is called exec, for example `kubectl exec pods/<name of pod> -- <command>` will run a command inside a running container. 
To get an interactive shell, you need to use the exec command: `kubectl exec --stdin --tty pods/<name of pod> -- <command>`. To get a shell for one of the hello-kubernetes pods you need to use this: `kubectl exec --stdin --tty pods/<name of pod> -- /bin/sh`.

Once you have a shell you can now run commands inside of it. Try using the `ls` command to list all files and folder inside the current directory. You may notice that this is a Node.js application. Try to list the contents of the `server.js` file using the `cat` command.

To exit the interactive shell write `exit` and hit the `ENTER` key or just close the terminal window.

You will now create an interactive container that is removed once you exit the shell. Run the following command: `kubectl run ubuntu --rm -i --tty --image ubuntu -- bash`. This will create a pod called "ubuntu" that will run the Ubuntu image. Once you exit the terminal the pod will be deleted.

Because the container is running inside the Kubernetes cluster you can now access services without using the port-forward command. 
To test this we first want to install the curl package - use `apt update && apt install curl -y` to install curl. Once curl is installed, write the following command to send an HTTP request to the hello-kubernetes service: `curl hello-kubernetes:8080`. The response will be the HTML for the hello-kubernetes webpage that you have seen earlier. You can try using the command multiple times and see how the response changes.

Because the service is inside the same namespace as your ubuntu container you can use the DNS entry `hello-kubernetes`. If you want to access a service in a different `namespace` you need to use a different `hostname`. Use the following command `curl hello-kubernetes.default:8080` where `default` is another namespace. NB: You will notice that you are not able to `curl` other namespaces.

Sometimes you don't want to delete the container when you exit the shell. Use the following command to create an ubuntu container that won't be deleted when you exit the shell: `kubectl run ubuntu -i --tty --image ubuntu -- bash`. To reattach the same shell again use one of the following command: `kubectl attach ubuntu -c ubuntu -i -t`. You can even open two terminals and use the attach command and the shell will be shared. Try to do this and write something in one shell and see how it is also written in the other.

You can also copy files to containers. Use the file on your localhost called `README.md`. Open a new terminal inside same directory, and use the following command to copy the `README.md` file to the ubuntu container: `kubectl cp README.md ubuntu:/README.md`. Open the other terminal again and use the `ls` and `cat` commands to verify the file was copied to the container.

### Exercise 7 - Cleaning up

Kubernetes resources can be deleted using the `kubectl delete` command. You can either delete individual resources, such as a hello-kubernetes deployment using the following command `kubectl delete deployment/hello-kubernetes`, or you can delete it using the file you used to create the resources with using the command `kubectl delete -f hello-kubernetes.yaml`.
> If you used Helm to create the resources then you should also delete it using Helm.

## Step-by-step guide to clean up

- To begin with, we will delete the first hello-kubernetes deployment that you made using the yaml manifest file: `kubectl delete -f hello-kubernetes.yaml`
- Next we will uninstall the hello-kubernetes release of the hello-kubernetes Helm chart: `helm uninstall hello-kubernetes-helm`
- Delete the ubuntu container: `kubectl delete pods/ubuntu`

You can get a list of the pods and services to verify that they are deleted.

- `kubectl get pods`
- `kubectl get services`
